{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32cf473b-df83-4b51-96f9-d1bad9b94e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "현재 탐색 티커: CDXC\n",
      "현재 탐색 티커: CDXS\n",
      "현재 탐색 티커: CDZI\n",
      "현재 탐색 티커: CE\n",
      "현재 탐색 티커: CEAD\n",
      "현재 탐색 티커: CECO\n",
      "현재 탐색 티커: CEF\n",
      "현재 탐색 티커: CEG\n",
      "현재 탐색 티커: CEIX\n",
      "현재 탐색 티커: CELC\n",
      "현재 탐색 티커: CELH\n",
      "현재 탐색 티커: CELU\n",
      "현재 탐색 티커: CELZ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m collector \u001b[38;5;241m=\u001b[39m TickerDataCollector(tickers_file, financial_results_file)  \u001b[38;5;66;03m# 객체 생성\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m collector\u001b[38;5;241m.\u001b[39mcollect_data()\n",
      "Cell \u001b[1;32mIn[2], line 97\u001b[0m, in \u001b[0;36mTickerDataCollector.collect_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtickers[start_ticker_index:]:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m현재 탐색 티커: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_data(ticker)  \u001b[38;5;66;03m# 웹 페이지 데이터 가져오기\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     value_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_table(soup)  \u001b[38;5;66;03m# 테이블 데이터 파싱\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_df\u001b[38;5;241m.\u001b[39mloc[ticker] \u001b[38;5;241m=\u001b[39m value_list  \u001b[38;5;66;03m# 데이터프레임에 추가\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m, in \u001b[0;36mTickerDataCollector.fetch_data\u001b[1;34m(self, ticker)\u001b[0m\n\u001b[0;32m     68\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m))  \u001b[38;5;66;03m# 재시도 전 3~5초 대기\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)  \u001b[38;5;66;03m# 다시 요청\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed()\n\u001b[0;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mfeed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     parser\u001b[38;5;241m.\u001b[39mfeed(markup)\n\u001b[0;32m    381\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\html\\parser.py:111\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoahead(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\html\\parser.py:171\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_starttag(i)\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    173\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\html\\parser.py:338\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_starttag(tag, attrs)\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:137\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m#print(\"START\", name)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m sourceline, sourcepos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetpos()\n\u001b[1;32m--> 137\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\u001b[38;5;241m.\u001b[39mhandle_starttag(\n\u001b[0;32m    138\u001b[0m     name, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, attr_dict, sourceline\u001b[38;5;241m=\u001b[39msourceline,\n\u001b[0;32m    139\u001b[0m     sourcepos\u001b[38;5;241m=\u001b[39msourcepos\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mand\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mis_empty_element \u001b[38;5;129;01mand\u001b[39;00m handle_empty_element:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# events for tags of this name.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:749\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    746\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melement_classes\u001b[38;5;241m.\u001b[39mget(Tag, Tag)(\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder, name, namespace, nsprefix, attrs,\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrentTag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_recent_element,\n\u001b[0;32m    752\u001b[0m     sourceline\u001b[38;5;241m=\u001b[39msourceline, sourcepos\u001b[38;5;241m=\u001b[39msourcepos,\n\u001b[0;32m    753\u001b[0m     namespaces\u001b[38;5;241m=\u001b[39mnamespaces\n\u001b[0;32m    754\u001b[0m )\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\element.py:1262\u001b[0m, in \u001b[0;36mTag.__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attrs:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mcdata_list_attributes:\n\u001b[1;32m-> 1262\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39m_replace_cdata_list_attribute_values(\n\u001b[0;32m   1263\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, attrs)\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\builder\\__init__.py:295\u001b[0m, in \u001b[0;36mTreeBuilder._replace_cdata_list_attribute_values\u001b[1;34m(self, tag_name, attrs)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set up any substitutions that will need to be performed on \u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    a `Tag` when it's output as a string.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    :return: Whether or not a substitution was performed.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_replace_cdata_list_attribute_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag_name, attrs):\n\u001b[0;32m    296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"When an attribute value is associated with a tag that can\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    have multiple values for that attribute, convert the string\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    value to a list of strings.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m       Any appropriate attribute values will be modified in place.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 티커 데이터를 수집하고 저장하는 클래스 정의\n",
    "class TickerDataCollector:\n",
    "    def __init__(self, tickers_file, financial_results_file):\n",
    "        # 클래스 초기화: 티커 파일 경로와 재무 결과 파일 경로 설정\n",
    "        self.tickers_file = tickers_file\n",
    "        self.financial_results_file = financial_results_file\n",
    "        self.tickers = self.load_tickers()  # 티커 목록 로드\n",
    "        self.results_df = self.load_results()  # 이전에 저장된 재무 데이터 로드\n",
    "\n",
    "    # 티커 목록을 로드하는 메서드\n",
    "    def load_tickers(self):\n",
    "        if os.path.exists(self.tickers_file):  # 파일 존재 여부 확인\n",
    "            df = pd.read_csv(self.tickers_file)  # CSV 파일 읽기\n",
    "            tickers = df[\"Tickers\"].tolist()  # 'Tickers' 열을 리스트로 변환\n",
    "            tickers = [str(x) for x in tickers]  # 모든 티커를 문자열로 변환\n",
    "            tickers.sort()  # 티커 정렬\n",
    "            return tickers  # 정렬된 티커 목록 반환\n",
    "        else:\n",
    "            # 파일이 존재하지 않을 경우 오류 발생\n",
    "            raise FileNotFoundError(f\"{self.tickers_file} not found.\")\n",
    "\n",
    "    # 이전에 저장된 재무 데이터를 로드하는 메서드\n",
    "    def load_results(self):\n",
    "        if os.path.exists(self.financial_results_file):  # 파일 존재 여부 확인\n",
    "            return pd.read_csv(self.financial_results_file, index_col=0)  # 기존 데이터프레임 로드\n",
    "        else:\n",
    "            # 파일이 없으면 새로운 데이터프레임 생성\n",
    "            columns = [\n",
    "                'Index', 'Market Cap', 'Income', 'Sales', 'Book/sh', 'Cash/sh', \n",
    "                'Dividend Est.', 'Dividend TTM', 'Dividend Ex-Date', 'Employees', \n",
    "                'Option/Short', 'Sales Surprise', 'SMA20', 'P/E', 'Forward P/E', \n",
    "                'PEG', 'P/S', 'P/B', 'P/C', 'P/FCF', 'Quick Ratio', 'Current Ratio', \n",
    "                'Debt/Eq', 'LT Debt/Eq', 'EPS Surprise', 'SMA50', 'EPS (ttm)', \n",
    "                'EPS next Y', 'EPS next Q', 'EPS this Y', 'EPS next 5Y', 'EPS past 5Y', \n",
    "                'Sales past 5Y', 'EPS Y/Y TTM', 'Sales Y/Y TTM', 'EPS Q/Q', 'Sales Q/Q', \n",
    "                'SMA200', 'Insider Own', 'Insider Trans', 'Inst Own', 'Inst Trans', \n",
    "                'ROA', 'ROE', 'ROI', 'Gross Margin', 'Oper. Margin', 'Profit Margin', \n",
    "                'Payout', 'Earnings', 'Trades', 'Shs Outstand', 'Shs Float', \n",
    "                'Short Float', 'Short Ratio', 'Short Interest', '52W Range', \n",
    "                '52W High', '52W Low', 'RSI (14)', 'Recom', 'Rel Volume', \n",
    "                'Avg Volume', 'Volume', 'Perf Week', 'Perf Month', 'Perf Quarter', \n",
    "                'Perf Half Y', 'Perf Year', 'Perf YTD', 'Beta', 'ATR (14)', \n",
    "                'Volatility', 'Target Price', 'Prev Close', 'Price', 'Change'\n",
    "            ]\n",
    "            return pd.DataFrame(columns=columns)  # 빈 데이터프레임 반환\n",
    "\n",
    "    # 웹 페이지에서 데이터를 가져오는 메서드\n",
    "    def fetch_data(self, ticker):\n",
    "        url = f'https://finviz.com/quote.ashx?t={ticker}&p=d'  # 요청할 URL 설정\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',\n",
    "            'Referer': 'https://example.com',\n",
    "            'Accept-Language': 'ko-KR,ko;q=0.9',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers)  # 웹 페이지 요청\n",
    "        while response.status_code == 429:  # 너무 많은 요청으로 차단된 경우\n",
    "            print(\"너무 많은 요청.. 재시도 중\")\n",
    "            time.sleep(random.uniform(3, 5))  # 재시도 전 3~5초 대기\n",
    "            response = requests.get(url, headers=headers)  # 다시 요청\n",
    "        return BeautifulSoup(response.text, \"html.parser\")  # HTML 파싱하여 반환\n",
    "\n",
    "    # HTML 테이블을 파싱하여 데이터 리스트로 변환하는 메서드\n",
    "    def parse_table(self, soup):\n",
    "        table = soup.find(\"table\", {\"class\": \"snapshot-table2\"})  # 테이블 찾기\n",
    "        rows = table.find_all(\"tr\")  # 모든 행 가져오기\n",
    "        table_data = []\n",
    "\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")  # 각 행의 모든 셀 가져오기\n",
    "            row_data = [cell.get_text(strip=True) for cell in cells]  # 텍스트 추출 및 공백 제거\n",
    "            table_data.append(row_data)  # 추출한 데이터 리스트에 추가\n",
    "        \n",
    "        # 데이터프레임으로 변환\n",
    "        df = pd.DataFrame(table_data).reset_index(drop=True)\n",
    "        value_list = []\n",
    "        for i in range(0, 12, 2):  # 필요한 데이터만 추출\n",
    "            value_list.extend(df[i + 1].tolist())  # 짝수 열의 데이터만 추가\n",
    "        return value_list  # 최종 데이터 리스트 반환\n",
    "\n",
    "    # 모든 티커에 대해 데이터를 수집하는 메서드\n",
    "    def collect_data(self):\n",
    "        start_ticker_index = len(self.results_df)  # 이미 수집된 데이터 개수\n",
    "        start_ticker = self.tickers[start_ticker_index]  # 시작할 티커\n",
    "\n",
    "        for ticker in self.tickers[start_ticker_index:]:\n",
    "            print(f\"현재 탐색 티커: {ticker}\")\n",
    "            soup = self.fetch_data(ticker)  # 웹 페이지 데이터 가져오기\n",
    "            value_list = self.parse_table(soup)  # 테이블 데이터 파싱\n",
    "            self.results_df.loc[ticker] = value_list  # 데이터프레임에 추가\n",
    "            self.save_results()  # 결과 저장\n",
    "\n",
    "    # 수집된 데이터를 CSV 파일에 저장하는 메서드\n",
    "    def save_results(self):\n",
    "        self.results_df.to_csv(self.financial_results_file, index=True)  # CSV 파일로 저장\n",
    "\n",
    "# 프로그램 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    tickers_file = 'tickers.csv'  # 티커 파일 경로\n",
    "    financial_results_file = 'financial_results.csv'  # 결과 파일 경로\n",
    "    print(\"test\")\n",
    "\n",
    "    collector = TickerDataCollector(tickers_file, financial_results_file)  # 객체 생성\n",
    "    collector.collect_data()  # 데이터 수집 시작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2d08c-42d7-4849-bcc6-3c10fcebced9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
